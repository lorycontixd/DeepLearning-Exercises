{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a736c2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot\n",
    "from dataclasses import dataclass\n",
    "from collections import deque\n",
    "\n",
    "# ML\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, losses, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3d1e2563",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class QSettings():\n",
    "    epsilon: float = 1.0\n",
    "    default_epsilon: float = epsilon\n",
    "    epsilon_min = 0.01\n",
    "    epsilon_decay = 0.99\n",
    "    discount: float = 0.9\n",
    "    learning_rate: float = 0.001\n",
    "        \n",
    "    def reset(self):\n",
    "        self.epsilon = self.default_epsilon\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b4dcdf83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.42945926372600585, 0.612431402464325)\n"
     ]
    }
   ],
   "source": [
    "testt = [ \n",
    "    np.array([0, 1], dtype=np.float32),  # radial movement\n",
    "    np.array([0, 2*np.pi], dtype=np.float32), # Anglular movement\n",
    "]\n",
    "neww = (np.random.uniform(testt[0][0], testt[0][1]), np.random.uniform(testt[1][0], testt[1][1]))\n",
    "print(neww)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8b6fc11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Math:\n",
    "    @staticmethod\n",
    "    def cartesian_to_polar(x,y):\n",
    "        return (np.sqrt(x*x + y*y), np.arctan2(y,x))\n",
    "    \n",
    "    @staticmethod\n",
    "    def polar_to_cartesian(r, theta):\n",
    "        return (r*np.cos(theta), r*np.sin(theta))\n",
    "    \n",
    "    @staticmethod\n",
    "    def distance(x1, x2, y1, y2):\n",
    "        return np.sqrt( np.power( (x2 - x1) , 2) + np.power( (y2 - y1 ) , 2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "319ce0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Character:\n",
    "    def __init__(self, x, y, health: float, attdmg: float):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.startingx = x\n",
    "        self.startingy = y\n",
    "        self.health = health\n",
    "        self.attdmg = attdmg\n",
    "\n",
    "# Move qsettings to agent (?)\n",
    "        \n",
    "class Agent(Character):\n",
    "    def __init__(self, env, x, y):\n",
    "        super().__init__(x,y, 200, 10)\n",
    "        self.env = env\n",
    "        self.memory = deque(maxlen=3000)\n",
    "        \n",
    "        self.actions = [ \n",
    "            np.array([0, 1], dtype=np.float32),  # radial movement\n",
    "            np.array([0, 2*np.pi], dtype=np.float32), # Anglular movement\n",
    "        ]\n",
    "        self.action_size = len(self.actions)\n",
    "        \n",
    "        self.state_size = 2 # (x, y)\n",
    "        \n",
    "        self.model = self._build_model()\n",
    "        self.target_model = self._build_model()\n",
    "        self.update_target_model()\n",
    "        \n",
    "        \n",
    "    def _build_model(self):\n",
    "        \"\"\"\n",
    "        Builds state-action DNN model\n",
    "        \"\"\"\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Dense(24, input_dim = self.state_size, activation='relu')) # state size is 2 (agent x, agent y)\n",
    "        model.add(layers.Dense(24, activation='relu'))\n",
    "        model.add(layers.Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=optimizers.Adam(lr=self.env.qsettings.learning_rate))\n",
    "        return model\n",
    "    \n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "        \n",
    "    def memorize(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        \n",
    "    \n",
    "    \n",
    "    # model must hold polar coordinates because it's relative to the action\n",
    "    def get_next_action(self, state):\n",
    "        if np.random.rand() <= self.env.qsettings.epsilon:\n",
    "            return (np.random.uniform(testt[0][0], testt[0][1]), np.random.uniform(testt[1][0], testt[1][1]))\n",
    "        act_values = self.model.predict(state)\n",
    "        return act_values\n",
    "    \n",
    "    def move(self, x, y, action):\n",
    "        assert isinstance(action, tuple)\n",
    "        assert len(action)==2\n",
    "        r = action[0]\n",
    "        theta = action[1]\n",
    "        newx, newy = Math.polar_to_cartesian(r, theta)\n",
    "        return newx, newy\n",
    "        \n",
    "    \n",
    "    def step(self, action):\n",
    "        self.x, self.y = self.move(self.x, self.y, action)\n",
    "        if len(self.env.nearby_enemies(self.x, self.y)) > 0:\n",
    "            reward = -20\n",
    "        elif self.env.is_end(self.x, self.y):\n",
    "            reward = 100\n",
    "        else:\n",
    "            reward = -1\n",
    "        state = (self.x, self.y)\n",
    "        done = self.env.is_end(self.x, self.y)\n",
    "        return (state, reward, done)\n",
    "        \n",
    "            \n",
    "        \n",
    "    \n",
    "    def replay(self, batch_size: int):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = self.model.predict(self.build_state(state))\n",
    "            if done:\n",
    "                target = reward\n",
    "            else:\n",
    "                t = self.target_model.predict(self.build_state(next_state))[0]\n",
    "                print(\"t= \",t)\n",
    "                target = reward + self.env.qsettings.discount * np.amax(t)\n",
    "                print(\"target= \",target)\n",
    "            self.model.fit(self.build_state(state), target, epochs=1, verbose=0)\n",
    "        if self.env.qsettings.epsilon > self.env.qsettings.epsilon_min:\n",
    "            self.env.qsettings.epsilon *= self.env.qsettings.epsilon_decay\n",
    "            \n",
    "    def build_state(self, *args):\n",
    "        if len(args)==2:\n",
    "            # x, y passed\n",
    "            x = args[0]\n",
    "            y = args[1]\n",
    "            return np.array([[x, y],])\n",
    "        elif len(args)==1:\n",
    "            # state passed\n",
    "            state = args[0]\n",
    "            return np.array([state,])\n",
    "            \n",
    "    def reset(self):\n",
    "        self.env.qsettings.reset()\n",
    "        # Reset state\n",
    "        self.x = self.startingx\n",
    "        self.y = self.startingy\n",
    "        return self.build_state(self.x, self.y)\n",
    "    \n",
    "    def train(self, epochs: int, max_time_limit: int, batch_size: int):\n",
    "        done = False\n",
    "        for epoch in range(epochs):\n",
    "            state = self.reset()\n",
    "            for time in range(max_time_limit):\n",
    "                print(f\"Running epoch {epoch}/{epochs-1} - time {time}/{max_time_limit-1}\", end='\\r',flush=True)\n",
    "                action = self.get_next_action(state)\n",
    "                next_state, reward, done = self.step(action)\n",
    "                self.memorize(state, action, reward, next_state, done)\n",
    "                state = next_state\n",
    "                if done:\n",
    "                    self.update_target_model()\n",
    "                    print(\"episode: {}/{}, score: {}/{}, e: {:.2}\"\n",
    "                      .format(epoch, epochs-1, time, max_time_limit-1, self.env.qsettings.epsilon))\n",
    "                    break\n",
    "                else:\n",
    "                    if len(self.memory) > batch_size:\n",
    "                        self.replay(batch_size)\n",
    "                \n",
    "        \n",
    "            \n",
    "        \n",
    "class Enemy(Character):\n",
    "    def __init__(self, x,y, radius=10):\n",
    "        super().__init__(x,y, 50, 7)\n",
    "        self.radius = radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d4d315a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment():\n",
    "    def __init__(self, mapsize: tuple = (30,30), timeout = 500, nenemies = 50, endpos: tuple = (0,0) , qsettings = QSettings()):\n",
    "        self.mapsize = mapsize\n",
    "        self.qsettings = qsettings\n",
    "        self.enemies = []\n",
    "        self.endpos = endpos\n",
    "        self._build_enemies(nenemies)\n",
    "    \n",
    "    def _build_enemies(self, nenemies):\n",
    "        x = np.random.uniform(0, self.mapsize[0], size=nenemies)\n",
    "        y = np.random.uniform(0, self.mapsize[1], size=nenemies)\n",
    "        for i in range(len(x)):\n",
    "            self.enemies.append(Enemy(x[i], y[i]))\n",
    "            \n",
    "    def nearby_enemies(self, x, y):\n",
    "        inrange_enemies = []\n",
    "        for enemy in self.enemies:\n",
    "            if Math.distance(x, enemy.x, y, enemy.y) < enemy.radius:\n",
    "                inrange_enemies.append(enemy)\n",
    "        return inrange_enemies \n",
    "    \n",
    "    def is_end(self, x, y):\n",
    "        if x == self.endpos[0] and y == self.endpos[1]:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "34962f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Environment(nenemies=55)\n",
    "a = Agent(e,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "be7f9538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=  [-0.00781407  0.0042919 ]63\n",
      "target=  -19.99613728877157\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, <class 'numpy.float64'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-69e9e9b7065b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-110-e5abb450b4e4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, max_time_limit, batch_size)\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-110-e5abb450b4e4>\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqsettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscount\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"target= \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqsettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqsettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon_min\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqsettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqsettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon_decay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1131\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m       data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[1;32m   1134\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1362\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1150\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_data_adapter_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m     self._adapter = adapter_cls(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    989\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    992\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         \"input: {}, {}\".format(\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, <class 'numpy.float64'>"
     ]
    }
   ],
   "source": [
    "a.train(100, 64, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879d60f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a736c2d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7b311dacca06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# ML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrewriter_config_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/pywrap_tfe.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tfe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0;31m# pylint: disable=wildcard-import,g-import-not-at-top,line-too-long,undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0;31m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Externally in opensource we must enable exceptions to load the shared object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot\n",
    "from dataclasses import dataclass\n",
    "from collections import deque\n",
    "\n",
    "# ML\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, losses, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1e2563",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class QSettings():\n",
    "    epsilon: float = 1.0\n",
    "    default_epsilon: float = epsilon\n",
    "    epsilon_min = 0.01\n",
    "    epsilon_decay = 0.99\n",
    "    discount: float = 0.9\n",
    "    learning_rate: float = 0.001\n",
    "        \n",
    "    def reset(self):\n",
    "        self.epsilon = self.default_epsilon\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dcdf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "testt = [ \n",
    "    np.array([0, 1], dtype=np.float32),  # radial movement\n",
    "    np.array([0, 2*np.pi], dtype=np.float32), # Anglular movement\n",
    "]\n",
    "neww = (np.random.uniform(testt[0][0], testt[0][1]), np.random.uniform(testt[1][0], testt[1][1]))\n",
    "print(neww)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6fc11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Math:\n",
    "    @staticmethod\n",
    "    def cartesian_to_polar(x,y):\n",
    "        return (np.sqrt(x*x + y*y), np.arctan2(y,x))\n",
    "    \n",
    "    @staticmethod\n",
    "    def polar_to_cartesian(r, theta):\n",
    "        return (r*np.cos(theta), r*np.sin(theta))\n",
    "    \n",
    "    @staticmethod\n",
    "    def distance(x1, x2, y1, y2):\n",
    "        return np.sqrt( np.power( (x2 - x1) , 2) + np.power( (y2 - y1 ) , 2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319ce0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Character:\n",
    "    def __init__(self, x, y, health: float, attdmg: float):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.startingx = x\n",
    "        self.startingy = y\n",
    "        self.health = health\n",
    "        self.attdmg = attdmg\n",
    "\n",
    "# Move qsettings to agent (?)\n",
    "        \n",
    "class Agent(Character):\n",
    "    def __init__(self, env, x, y):\n",
    "        super().__init__(x,y, 200, 10)\n",
    "        self.env = env\n",
    "        self.memory = deque(maxlen=3000)\n",
    "        \n",
    "        self.actions = [ \n",
    "            np.array([0, 1], dtype=np.float32),  # radial movement\n",
    "            np.array([0, 2*np.pi], dtype=np.float32), # Anglular movement\n",
    "        ]\n",
    "        self.action_size = len(self.actions)\n",
    "        \n",
    "        self.state_size = 2 # (x, y)\n",
    "        \n",
    "        self.model = self._build_model()\n",
    "        self.target_model = self._build_model()\n",
    "        self.update_target_model()\n",
    "        \n",
    "        \n",
    "    def _build_model(self):\n",
    "        \"\"\"\n",
    "        Builds state-action DNN model\n",
    "        \"\"\"\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Dense(24, input_dim = self.state_size, activation='relu')) # state size is 2 (agent x, agent y)\n",
    "        model.add(layers.Dense(24, activation='relu'))\n",
    "        model.add(layers.Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=optimizers.Adam(lr=self.env.qsettings.learning_rate))\n",
    "        return model\n",
    "    \n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "        \n",
    "    def memorize(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        \n",
    "    \n",
    "    \n",
    "    # model must hold polar coordinates because it's relative to the action\n",
    "    def get_next_action(self, state):\n",
    "        if np.random.rand() <= self.env.qsettings.epsilon:\n",
    "            return (np.random.uniform(testt[0][0], testt[0][1]), np.random.uniform(testt[1][0], testt[1][1]))\n",
    "        act_values = self.model.predict(state)\n",
    "        return act_values\n",
    "    \n",
    "    def move(self, x, y, action):\n",
    "        assert isinstance(action, tuple)\n",
    "        assert len(action)==2\n",
    "        r = action[0]\n",
    "        theta = action[1]\n",
    "        newx, newy = Math.polar_to_cartesian(r, theta)\n",
    "        return newx, newy\n",
    "        \n",
    "    \n",
    "    def step(self, action):\n",
    "        self.x, self.y = self.move(self.x, self.y, action)\n",
    "        if len(self.env.nearby_enemies(self.x, self.y)) > 0:\n",
    "            reward = -20\n",
    "        elif self.env.is_end(self.x, self.y):\n",
    "            reward = 100\n",
    "        else:\n",
    "            reward = -1\n",
    "        state = (self.x, self.y)\n",
    "        done = self.env.is_end(self.x, self.y)\n",
    "        return (state, reward, done)\n",
    "        \n",
    "            \n",
    "        \n",
    "    \n",
    "    def replay(self, batch_size: int):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = self.model.predict(state)\n",
    "            if done:\n",
    "                target[0][action] = reward\n",
    "            else:\n",
    "                t = self.target_model.predict(next_state)[0]\n",
    "                trarget[0][actoin] = reward + self.qsettings.discount * np.amax(t)\n",
    "            self.model.fit(state, target, epochs=1, verbose=0)\n",
    "        if self.qsettings.epsilon > self.qsettings.epsilon_min:\n",
    "            self.qsettings.epsilon *= self.qsettings.epsilon_decay\n",
    "            \n",
    "    def build_state(self, x, y):\n",
    "        return np.array([x,y]), {}\n",
    "            \n",
    "    def reset(self):\n",
    "        self.env.qsettings.reset()\n",
    "        # Reset state\n",
    "        self.x = self.startingx\n",
    "        self.y = self.startingy\n",
    "        return self.build_state(self.x, self.y)\n",
    "    \n",
    "    def train(self, epochs: int, max_time_limit: int, batch_size: int):\n",
    "        done = False\n",
    "        for epoch in range(epochs):\n",
    "            state = self.reset()\n",
    "            for time in range(max_time_limit):\n",
    "                print(f\"Running epoch {epoch}/{epochs-1} - time {time}/{max_time_limit-1}\", end='\\r',flush=True)\n",
    "                action = self.get_next_action(state)\n",
    "                next_state, reward, done = self.step(action)\n",
    "                self.memorize(state, action, reward, next_state, done)\n",
    "                state = next_state\n",
    "                if done:\n",
    "                    self.update_target_model()\n",
    "                    print(\"episode: {}/{}, score: {}/{}, e: {:.2}\"\n",
    "                      .format(epoch, epochs-1, time, max_time_limit-1, self.env.qsettings.epsilon))\n",
    "                else:\n",
    "                    self.replay(batch_size)\n",
    "                \n",
    "        \n",
    "            \n",
    "        \n",
    "class Enemy(Character):\n",
    "    def __init__(self, x,y, radius=10):\n",
    "        super().__init__(x,y, 50, 7)\n",
    "        self.radius = radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d315a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment():\n",
    "    def __init__(self, mapsize: tuple = (30,30), timeout = 500, nenemies = 50, endpos: tuple = (0,0) , qsettings = QSettings()):\n",
    "        self.mapsize = mapsize\n",
    "        self.qsettings = qsettings\n",
    "        self.enemies = []\n",
    "        self.endpos = endpos\n",
    "        self._build_enemies(nenemies)\n",
    "    \n",
    "    def _build_enemies(self, nenemies):\n",
    "        x = np.random.uniform(0, self.mapsize[0], size=nenemies)\n",
    "        y = np.random.uniform(0, self.mapsize[1], size=nenemies)\n",
    "        for i in range(len(x)):\n",
    "            self.enemies.append(Enemy(x[i], y[i]))\n",
    "            \n",
    "    def nearby_enemies(self, x, y):\n",
    "        inrange_enemies = []\n",
    "        for enemy in self.enemies:\n",
    "            if Math.distance(x, enemy.x, y, enemy.y) < enemy.radius:\n",
    "                inrange_enemies.append(enemy)\n",
    "        return inrange_enemies \n",
    "    \n",
    "    def is_end(self, x, y):\n",
    "        if x == self.endpos[0] and y == self.endpos[1]:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34962f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Environment(nenemies=55)\n",
    "a = Agent(e,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7f9538",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.train(100, 64, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879d60f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "862f27d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from collections import deque\n",
    "from pprint import pprint\n",
    "from enum import Enum\n",
    "from typing import Union\n",
    "\n",
    "# IPython\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#ML\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, losses, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "84c7a090",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Math:\n",
    "    @staticmethod\n",
    "    def distance(x1, x2, y1, y2):\n",
    "        return np.sqrt( np.power( (x2-x1), 2.) + np.power( (y2-y1), 2.) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e838c48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionType(Enum):\n",
    "    MOVEMENT = 0\n",
    "    ACTION = 1\n",
    "\n",
    "@dataclass\n",
    "class Action:\n",
    "    type: ActionType\n",
    "    value: Union[int, str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84af1772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment\n",
    "\n",
    "@dataclass\n",
    "class QSettings():\n",
    "    epsilon: float\n",
    "    epsilon_min = 0.01\n",
    "    epsilon_decay = 0.99\n",
    "    discount: float\n",
    "    learning_rate: float\n",
    "     \n",
    "    \n",
    "@dataclass\n",
    "class Timer:\n",
    "    start: float\n",
    "    end: float\n",
    "    timer: float\n",
    "        \n",
    "        \n",
    "class RunInfo:\n",
    "    def __init__(self, nepisodes, ntimes):\n",
    "        self.timerstart = None\n",
    "        self.timerend = None\n",
    "        self.timertime = None\n",
    "        \n",
    "        self.scores = {str(i):[] for i in range(nepisodes)}\n",
    "    \n",
    "    def start_timer(self):\n",
    "        self.timerstart = time.time()\n",
    "    \n",
    "    def end_timer(self):\n",
    "        if self.timerstart is not None:\n",
    "            self.timerend = time.time()\n",
    "            self.timertime = self.timerend - self.timerend\n",
    "    \n",
    "    def get_timer(self):\n",
    "        if self.timertime is not None:\n",
    "            return self.timerend - self.timerstart\n",
    "        else:\n",
    "            raise ValueError(\"No timer is saved\")\n",
    "    \n",
    "    def reset_timer(self):\n",
    "        self.timerstart = None\n",
    "        self.timerend = None\n",
    "        self.timertime = None\n",
    "    \n",
    "    def add_score(self, episode, time, score):\n",
    "        self.scores[str(episode)].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d22106bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Character:\n",
    "    def __init__(self, x, y, health: float, attdmg: float):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.startx = x\n",
    "        self.starty = y\n",
    "        self.health = health\n",
    "        self.attdmg = attdmg\n",
    "\n",
    "class Agent(Character):\n",
    "    def __init__(self, env, x, y, qsettings: QSettings):\n",
    "        super().__init__(x,y, 300, 20)\n",
    "        self.env = env\n",
    "        self.x, self.y = self._set_valid_start(self.x, self.y)\n",
    "        self.actions = ['up', 'down', 'left', 'right']\n",
    "        self.nstates = 2 # vertical movement (rows), horizontal movement (cols)\n",
    "        self.qsettings = qsettings\n",
    "        \n",
    "        self.memory = deque(maxlen=50000)\n",
    "        self.qtable = np.zeros((self.env.nrows, self.env.ncols, len(self.actions))) # nrows x ncols x nactions\n",
    "        \n",
    "        self.model = self.__build_model__()\n",
    "        self.target_model = self.__build_model__()\n",
    "        self.update_target_model()\n",
    "        \n",
    "    def _get_random_valid_pos(self):\n",
    "        x = -1\n",
    "        y = -1\n",
    "        while (self.env.is_end(x,y) or self.env.is_enemy(x,y)) or x == -1 or y == -1:\n",
    "            x = np.random.randint(0, self.env.nrows)\n",
    "            y = np.random.randint(0, self.env.ncols)\n",
    "        return x, y\n",
    "        \n",
    "    def _set_valid_start(self, x, y):\n",
    "        if self.env.is_end(x,y) or self.env.is_enemy(x,y):\n",
    "            return self._get_random_valid_pos()\n",
    "        else:\n",
    "            return x, y\n",
    "        \n",
    "    def _check_valid_start(self, x, y):\n",
    "        return not (self.env.is_end(x,y) or self.env.is_enemy(x,y))\n",
    "    \n",
    "    def __build_model__(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Dense(50, input_dim=self.nstates, activation='relu'))\n",
    "        model.add(layers.Dense(50, activation='relu'))\n",
    "        model.add(layers.Dense(len(self.actions), activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=optimizers.Adam(lr=self.qsettings.learning_rate))\n",
    "        return model\n",
    "    \n",
    "    def set_starting_pos(self, *args):\n",
    "        if len(args) == 1:\n",
    "            # (x,y) as tuple\n",
    "            self.startx, self.starty = args[0]\n",
    "            if not self._check_valid_start(args[0][0], args[0][1]):\n",
    "                raise ValueError(\"Agent starting position is invalid\")\n",
    "        elif len(args) == 2:\n",
    "            # x,y as split params\n",
    "            if not self._check_valid_start(args[0], args[1]):\n",
    "                raise ValueError(\"Agent starting position is invalid\")\n",
    "            self.startx = args[0]\n",
    "            self.starty = args[1]\n",
    "        else:\n",
    "            raise ValueError(\"[SetStartingPos] Invalid number of arguments passed\")\n",
    "    \n",
    "    def update_target_model(self):\n",
    "        # copy weights from model to target_model\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "        \n",
    "    def memorize(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def get_next_action(self, state):\n",
    "        \"\"\"Next action is decided based on the epsilon-greedy algorithm.\n",
    "        If a random number is smaller than a value epsilon, the max value from the queue table is selected.\n",
    "        Otherwise, if the random number is larger, pick a random action\n",
    "        \"\"\"\n",
    "        if np.random.random() <= self.qsettings.epsilon:\n",
    "            return np.random.randint(len(self.actions))\n",
    "        else:\n",
    "            act_values = self.model.predict(state) # Main difference between vanilla q-learning and DQL\n",
    "            return np.argmax(act_values[0])\n",
    "            \n",
    "    \n",
    "    def get_next_location(self,current_row_index, current_column_index, action_index: int):\n",
    "        new_row_index = current_row_index\n",
    "        new_column_index = current_column_index\n",
    "        if self.actions[action_index] == 'up' and current_row_index > 0:\n",
    "            new_row_index -= 1\n",
    "        elif self.actions[action_index] == 'right' and current_column_index < self.env.ncols - 1:\n",
    "            new_column_index += 1\n",
    "        elif self.actions[action_index] == 'down' and current_row_index < self.env.nrows - 1:\n",
    "            new_row_index += 1\n",
    "        elif self.actions[action_index] == 'left' and current_column_index > 0:\n",
    "            new_column_index -= 1\n",
    "        return new_row_index, new_column_index\n",
    "    \n",
    "    def reset(self, randomizepos):\n",
    "        if randomizepos:\n",
    "            self.startx, self.starty = self._get_random_valid_pos()\n",
    "            self.x = self.startx\n",
    "            self.y = self.starty\n",
    "        else:\n",
    "            self.set_starting_pos(self.startx, self.starty)\n",
    "        return self.build_state(self.x, self.y)\n",
    "        \n",
    "    def build_state(self, *args):\n",
    "        if len(args)==1:\n",
    "            # state\n",
    "            state = args[0]\n",
    "            return np.array([state,]) \n",
    "        elif len(args)==2:\n",
    "            # x, y\n",
    "            x = args[0]\n",
    "            y = args[1]\n",
    "            return np.array([[x, y],])  \n",
    "        else:\n",
    "            raise ValueError(\"[BuildState] Invalid number of arguments passed\")\n",
    "    \n",
    "    def step(self, actionindex):\n",
    "        # Take the step and calculate new state\n",
    "        self.x, self.y = self.get_next_location(self.x, self.y, actionindex)\n",
    "        newstate = self.build_state(self.x, self.y)\n",
    "        # Calculate reward\n",
    "        reward = self.env.rewards[self.x][self.y]\n",
    "        done = self.env.is_end(self.x, self.y) or self.env.is_enemy(self.x, self.y)\n",
    "        return newstate, reward, done\n",
    "    \n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = self.model.predict(state)\n",
    "            if done:\n",
    "                target[0][action] = reward\n",
    "            else:\n",
    "                t = self.target_model.predict(next_state)[0]\n",
    "                target[0][action] = reward + self.qsettings.discount * np.amax(t)\n",
    "            self.model.fit(state, target, epochs=1, verbose=0)\n",
    "        if self.qsettings.epsilon > self.qsettings.epsilon_min:\n",
    "            self.qsettings.epsilon *= self.qsettings.epsilon_decay\n",
    "    \n",
    "    def trainDNN(self, epochs: int, epoch_max_time: int, batch_size: int, randomizepos: bool = True, verbose: bool = False):\n",
    "        self.runinfo = RunInfo(epochs, epoch_max_time)\n",
    "        self.runinfo.start_timer()\n",
    "        for epoch in range(epochs):\n",
    "            state = self.reset(randomizepos)\n",
    "            done = False\n",
    "            for time in range(epoch_max_time):\n",
    "                print(f\"Running time {time+1}/{epoch_max_time} for epoch {epoch+1}/{epochs}\", end='\\r', flush=True)\n",
    "                ### Choose an action using the epsilon-greedy algorithm\n",
    "                actionindex = self.get_next_action(state)\n",
    "                newstate, reward, done = self.step(actionindex)\n",
    "                # Store transition ( s,a,r,s',done )\n",
    "                self.memorize(state, actionindex, reward, newstate, done)\n",
    "                state = newstate\n",
    "                if done:\n",
    "                    self.update_target_model()\n",
    "                    print(\"episode: {}/{}, score: {}, e: {:.2}\"\n",
    "                          .format(epoch+1, epochs, time+1, self.qsettings.epsilon))\n",
    "                    break\n",
    "                else:\n",
    "                    if len(self.memory) > batch_size: # If enough experiences in memory -> replay\n",
    "                        self.replay(batch_size)\n",
    "                self.runinfo.add_score(epoch, time, self.qsettings.epsilon)\n",
    "        self.runinfo.end_timer()\n",
    "        traintime = self.runinfo.get_timer()\n",
    "        self.trained = True\n",
    "        print(f\"Train completed in {traintime} seconds\")\n",
    "        \n",
    "    \n",
    "    def run(self, startingpos: tuple, maxiterations: int = 10000, verbose: bool = False):\n",
    "        self.set_starting_pos(startingpos)\n",
    "        if self.env.is_enemy(self.startx, self.starty) or self.env.is_end(self.startx, self.starty):\n",
    "            return []\n",
    "        else:\n",
    "            state = self.reset(False)\n",
    "            shortestpath = []\n",
    "            shortestpath.append((self.startx, self.starty))\n",
    "            #i: int = 0\n",
    "            while not (self.env.is_end(self.x, self.y) or self.env.is_enemy(self.x, self.y)):\n",
    "                actionindex = self.get_next_action(state)\n",
    "                self.x, self.y = self.get_next_location(self.x, self.y, actionindex)\n",
    "                shortestpath.append((self.x, self.y))\n",
    "                print(f\"({self.x},{self.y})\", end='\\r',flush=True)\n",
    "                #i+=1\n",
    "                #if (i >= maxiterations):\n",
    "                #    print(f\"Reached maximum iterations {maxiterations}. Current position: ({self.x},{self.y})\")\n",
    "                #    return []\n",
    "            self.ran = True\n",
    "            return shortestpath\n",
    "    \n",
    "\n",
    "    \n",
    "class Enemy(Character):\n",
    "    def __init__(self, x, y, radius = 3) -> None:\n",
    "        super().__init__(x,y)\n",
    "        self.radius = radius\n",
    "        \n",
    "    def inrange(self, x,y):\n",
    "        return Math.distance(x,self.x, y, self.y) <= self.radius\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9556fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment():\n",
    "    def __init__(self, nrows: int, ncols: int, starting_location: tuple, end_location: tuple, nenemies: int, ):\n",
    "        self.nrows = nrows\n",
    "        self.ncols = ncols\n",
    "        self.mapsize = (nrows, ncols)\n",
    "        self.end_location = end_location\n",
    "        self.endrow, self.endcol = self.end_location\n",
    "        self.nenemies = nenemies\n",
    "        \n",
    "        \n",
    "        self.enemies = []\n",
    "        self.rewards = np.full((self.nrows, self.ncols), -1.)\n",
    "        \n",
    "        self.basereward = -1\n",
    "        self.enemyreward = -300\n",
    "        self.endreward = 300\n",
    "        \n",
    "        self.__build_enemies__()\n",
    "        self.__build_rewards__()\n",
    "    \n",
    "        \n",
    "    def __build_enemies__(self):\n",
    "        if len(self.enemies) <= 0:\n",
    "            while len(self.enemies) < self.nenemies:\n",
    "                randx = np.random.randint(self.nrows)\n",
    "                randy = np.random.randint(self.ncols)\n",
    "                if (randx, randy) not in self.enemies:\n",
    "                    if (randx,randy) != self.end_location:\n",
    "                        self.enemies.append((randx, randy))\n",
    "                        \n",
    "    def __build_rewards__(self):\n",
    "        for enemy in self.enemies:\n",
    "            ob_x, ob_y = enemy\n",
    "            self.rewards[ob_x][ob_y] = self.enemyreward\n",
    "        self.rewards[self.end_location[0]][self.end_location[1]] = self.endreward\n",
    "    \n",
    "    \n",
    "    def is_enemy(self, x, y):\n",
    "        return self.rewards[x][x] == self.enemyreward\n",
    "    def is_end(self, x, y):\n",
    "        return self.rewards[x][y] == self.endreward\n",
    "    \n",
    "    def showmap(self):\n",
    "        if len(self.enemies) > 0:\n",
    "            fig, ax = plt.subplots(figsize=(9,9))\n",
    "            ax.set_title(\"Reward map\")\n",
    "            ax.set_xlabel(\"col\")\n",
    "            ax.set_ylabel(\"row\")\n",
    "            rewardmap = self.rewards\n",
    "            ax.imshow(rewardmap)\n",
    "            plt.show()      \n",
    "    \n",
    "    def showpath(self, startpos: tuple, shortestpath: list):\n",
    "        if len(shortestpath) > 0:\n",
    "            newmap = self.rewards\n",
    "            newmap[startpos[0]][startpos[1]] = -50\n",
    "            for pos in shortestpath:\n",
    "                r, c = pos\n",
    "                newmap[r][c] = 100\n",
    "            fig, ax = plt.subplots(figsize=(9,9))\n",
    "            ax.set_title(\"Reward map\")\n",
    "            ax.set_xlabel(\"col\")\n",
    "            ax.set_ylabel(\"row\")\n",
    "            ax.imshow(newmap)\n",
    "            plt.show()\n",
    "    \n",
    "    def save(self, name): \n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f6855dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Environment(\n",
    "    30,30,\n",
    "    (1,1),\n",
    "    (28,28),\n",
    "    100\n",
    ")\n",
    "\n",
    "agentqsettings = QSettings(epsilon=0.9, discount=0.4, learning_rate=0.001)\n",
    "a = Agent(e, 1, 1, agentqsettings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "19552e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "e.showmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eb941ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1/100, score: 8, e: 0.90\n",
      "episode: 2/100, score: 1, e: 0.90\n",
      "episode: 3/100, score: 1, e: 0.90\n",
      "episode: 4/100, score: 1, e: 0.90\n",
      "episode: 5/100, score: 1, e: 0.90\n",
      "episode: 6/100, score: 1, e: 0.90\n",
      "episode: 7/100, score: 6, e: 0.90\n",
      "episode: 8/100, score: 3, e: 0.90\n",
      "episode: 9/100, score: 1, e: 0.90\n",
      "episode: 10/100, score: 36, e: 0.69\n",
      "episode: 11/100, score: 28, e: 0.53\n",
      "episode: 12/100, score: 11, e: 0.48\n",
      "episode: 13/100, score: 1, e: 0.48\n",
      "episode: 14/100, score: 1, e: 0.48\n",
      "episode: 15/100, score: 1, e: 0.48\n",
      "episode: 16/100, score: 1, e: 0.48\n",
      "episode: 17/100, score: 1, e: 0.48\n",
      "episode: 18/100, score: 10, e: 0.44\n",
      "episode: 19/100, score: 1, e: 0.44\n",
      "episode: 20/100, score: 1, e: 0.44\n",
      "episode: 21/100, score: 20, e: 0.36\n",
      "episode: 22/100, score: 29, e: 0.27\n",
      "episode: 23/100, score: 2, e: 0.27\n",
      "episode: 24/100, score: 15, e: 0.23\n",
      "episode: 25/100, score: 5, e: 0.22\n",
      "episode: 26/100, score: 3, e: 0.22\n",
      "episode: 27/100, score: 6, e: 0.21\n",
      "episode: 28/100, score: 4, e: 0.20\n",
      "episode: 29/100, score: 25, e: 0.16\n",
      "episode: 30/100, score: 1, e: 0.16\n",
      "episode: 31/100, score: 2, e: 0.16\n",
      "episode: 32/100, score: 2, e: 0.16\n",
      "episode: 33/100, score: 2, e: 0.16\n",
      "episode: 37/100, score: 10, e: 0.042\n",
      "episode: 41/100, score: 8, e: 0.012\n",
      "episode: 42/100, score: 2, e: 0.012\n",
      "episode: 43/100, score: 2, e: 0.012\n",
      "episode: 44/100, score: 2, e: 0.011\n",
      "episode: 45/100, score: 2, e: 0.011\n",
      "episode: 46/100, score: 8, e: 0.011\n",
      "episode: 47/100, score: 2, e: 0.01\n",
      "episode: 48/100, score: 1, e: 0.01\n",
      "episode: 49/100, score: 1, e: 0.01\n",
      "episode: 50/100, score: 17, e: 0.01\n",
      "episode: 51/100, score: 1, e: 0.01\n",
      "episode: 52/100, score: 23, e: 0.01\n",
      "episode: 53/100, score: 1, e: 0.01\n",
      "episode: 54/100, score: 37, e: 0.01\n",
      "episode: 55/100, score: 1, e: 0.01\n",
      "episode: 56/100, score: 1, e: 0.01\n",
      "episode: 57/100, score: 1, e: 0.01\n",
      "episode: 58/100, score: 1, e: 0.01\n",
      "episode: 59/100, score: 1, e: 0.01\n",
      "episode: 60/100, score: 1, e: 0.01\n",
      "episode: 61/100, score: 1, e: 0.01\n",
      "episode: 62/100, score: 1, e: 0.01\n",
      "episode: 63/100, score: 1, e: 0.01\n",
      "episode: 64/100, score: 1, e: 0.01\n",
      "episode: 65/100, score: 1, e: 0.01\n",
      "episode: 66/100, score: 1, e: 0.01\n",
      "episode: 67/100, score: 1, e: 0.01\n",
      "episode: 68/100, score: 1, e: 0.01\n",
      "episode: 69/100, score: 1, e: 0.01\n",
      "episode: 70/100, score: 1, e: 0.01\n",
      "episode: 71/100, score: 1, e: 0.01\n",
      "episode: 72/100, score: 1, e: 0.01\n",
      "episode: 73/100, score: 2, e: 0.01\n",
      "episode: 74/100, score: 1, e: 0.01\n",
      "episode: 75/100, score: 1, e: 0.01\n",
      "episode: 76/100, score: 1, e: 0.01\n",
      "episode: 77/100, score: 1, e: 0.01\n",
      "episode: 78/100, score: 1, e: 0.01\n",
      "episode: 79/100, score: 1, e: 0.01\n",
      "episode: 80/100, score: 1, e: 0.01\n",
      "episode: 81/100, score: 1, e: 0.01\n",
      "episode: 82/100, score: 1, e: 0.01\n",
      "episode: 83/100, score: 1, e: 0.01\n",
      "episode: 84/100, score: 1, e: 0.01\n",
      "episode: 85/100, score: 1, e: 0.01\n",
      "episode: 86/100, score: 1, e: 0.01\n",
      "episode: 87/100, score: 1, e: 0.01\n",
      "episode: 88/100, score: 1, e: 0.01\n",
      "episode: 89/100, score: 1, e: 0.01\n",
      "episode: 90/100, score: 1, e: 0.01\n",
      "episode: 91/100, score: 1, e: 0.01\n",
      "episode: 92/100, score: 1, e: 0.01\n",
      "episode: 93/100, score: 1, e: 0.01\n",
      "episode: 94/100, score: 1, e: 0.01\n",
      "episode: 95/100, score: 1, e: 0.01\n",
      "episode: 96/100, score: 1, e: 0.01\n",
      "episode: 97/100, score: 1, e: 0.01\n",
      "episode: 98/100, score: 1, e: 0.01\n",
      "episode: 99/100, score: 1, e: 0.01\n",
      "episode: 100/100, score: 1, e: 0.01\n",
      "Train completed in 1139.763555765152 seconds\n"
     ]
    }
   ],
   "source": [
    "a.trainDNN(100, 40, 32, False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f58535b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "startpos = (24,1)\n",
    "shortestpath = a.run(startpos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d26e9279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(24, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(shortestpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5288f5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "e.showpath(startpos, shortestpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fe9a5c3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(24, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(shortestpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb8951e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

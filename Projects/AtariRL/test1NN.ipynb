{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "862f27d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from collections import deque\n",
    "from pprint import pprint\n",
    "from enum import Enum\n",
    "from typing import Union\n",
    "\n",
    "# IPython\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#ML\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, losses, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84c7a090",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Math:\n",
    "    @staticmethod\n",
    "    def distance(x1, x2, y1, y2):\n",
    "        return np.sqrt( np.power( (x2-x1), 2.) + np.power( (y2-y1), 2.) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e838c48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionType(Enum):\n",
    "    MOVEMENT = 0\n",
    "    ACTION = 1\n",
    "\n",
    "@dataclass\n",
    "class Action:\n",
    "    type: ActionType\n",
    "    value: Union[int, str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84af1772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment\n",
    "\n",
    "@dataclass\n",
    "class QSettings():\n",
    "    epsilon: float\n",
    "    epsilon_min = 0.01\n",
    "    epsilon_decay = 0.99\n",
    "    discount: float\n",
    "    learning_rate: float\n",
    "     \n",
    "    \n",
    "@dataclass\n",
    "class Timer:\n",
    "    start: float\n",
    "    end: float\n",
    "    timer: float\n",
    "        \n",
    "        \n",
    "class RunInfo:\n",
    "    def __init__(self, nepisodes, ntimes):\n",
    "        self.timerstart = None\n",
    "        self.timerend = None\n",
    "        self.timertime = None\n",
    "        \n",
    "        self.scores = {str(i):[] for i in range(nepisodes)}\n",
    "    \n",
    "    def start_timer(self):\n",
    "        self.timerstart = time.time()\n",
    "    \n",
    "    def end_timer(self):\n",
    "        if self.timerstart is not None:\n",
    "            self.timerend = time.time()\n",
    "            self.timertime = self.timerend - self.timerend\n",
    "    \n",
    "    def get_timer(self):\n",
    "        if self.timertime is not None:\n",
    "            return self.timerend - self.timerstart\n",
    "        else:\n",
    "            raise ValueError(\"No timer is saved\")\n",
    "    \n",
    "    def reset_timer(self):\n",
    "        self.timerstart = None\n",
    "        self.timerend = None\n",
    "        self.timertime = None\n",
    "    \n",
    "    def add_score(self, episode, time, score):\n",
    "        self.scores[str(episode)].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d22106bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Character:\n",
    "    def __init__(self, x, y, health: float, attdmg: float):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.startx = x\n",
    "        self.starty = y\n",
    "        self.health = health\n",
    "        self.attdmg = attdmg\n",
    "\n",
    "class Agent(Character):\n",
    "    def __init__(self, env, x, y, qsettings: QSettings):\n",
    "        super().__init__(x,y, 300, 20)\n",
    "        self.env = env\n",
    "        self.x, self.y = self._set_valid_start(self.x, self.y)\n",
    "        self.actions = ['up', 'down', 'left', 'right']\n",
    "        self.nstates = 2 # vertical movement (rows), horizontal movement (cols)\n",
    "        self.qsettings = qsettings\n",
    "        \n",
    "        self.memory = deque(maxlen=50000)\n",
    "        self.qtable = np.zeros((self.env.nrows, self.env.ncols, len(self.actions))) # nrows x ncols x nactions\n",
    "        \n",
    "        self.model = self.__build_model__()\n",
    "        self.target_model = self.__build_model__()\n",
    "        self.update_target_model()\n",
    "        \n",
    "    def _get_random_valid_pos(self):\n",
    "        x = -1\n",
    "        y = -1\n",
    "        while (self.env.is_end(x,y) or self.env.is_enemy(x,y)) or x == -1 or y == -1:\n",
    "            x = np.random.randint(0, self.env.nrows)\n",
    "            y = np.random.randint(0, self.env.ncols)\n",
    "        return x, y\n",
    "        \n",
    "    def _set_valid_start(self, x, y):\n",
    "        if self.env.is_end(x,y) or self.env.is_enemy(x,y):\n",
    "            return self._get_random_valid_pos()\n",
    "        else:\n",
    "            return x, y\n",
    "        \n",
    "    def _check_valid_start(self, x, y):\n",
    "        return not (self.env.is_end(x,y) or self.env.is_enemy(x,y))\n",
    "    \n",
    "    def __build_model__(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Dense(50, input_dim=self.nstates, activation='relu'))\n",
    "        model.add(layers.Dense(50, activation='relu'))\n",
    "        model.add(layers.Dense(len(self.actions), activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=optimizers.Adam(lr=self.qsettings.learning_rate))\n",
    "        return model\n",
    "    \n",
    "    def set_starting_pos(self, *args):\n",
    "        if len(args) == 1:\n",
    "            # (x,y) as tuple\n",
    "            self.startx, self.starty = args[0]\n",
    "            if not self._check_valid_start(args[0][0], args[0][1]):\n",
    "                raise ValueError(\"Agent starting position is invalid\")\n",
    "        elif len(args) == 2:\n",
    "            # x,y as split params\n",
    "            if not self._check_valid_start(args[0], args[1]):\n",
    "                raise ValueError(\"Agent starting position is invalid\")\n",
    "            self.startx = args[0]\n",
    "            self.starty = args[1]\n",
    "        else:\n",
    "            raise ValueError(\"[SetStartingPos] Invalid number of arguments passed\")\n",
    "    \n",
    "    def update_target_model(self):\n",
    "        # copy weights from model to target_model\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "        \n",
    "    def memorize(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def get_next_action(self, state):\n",
    "        \"\"\"Next action is decided based on the epsilon-greedy algorithm.\n",
    "        If a random number is smaller than a value epsilon, the max value from the queue table is selected.\n",
    "        Otherwise, if the random number is larger, pick a random action\n",
    "        \"\"\"\n",
    "        if np.random.random() <= self.qsettings.epsilon:\n",
    "            return np.random.randint(len(self.actions))\n",
    "        else:\n",
    "            act_values = self.model.predict(state, verbose=0) # Main difference between vanilla q-learning and DQL\n",
    "            return np.argmax(act_values[0])\n",
    "            \n",
    "    \n",
    "    def get_next_location(self,current_row_index, current_column_index, action_index: int):\n",
    "        new_row_index = current_row_index\n",
    "        new_column_index = current_column_index\n",
    "        if self.actions[action_index] == 'up' and current_row_index > 0:\n",
    "            new_row_index -= 1\n",
    "        elif self.actions[action_index] == 'right' and current_column_index < self.env.ncols - 1:\n",
    "            new_column_index += 1\n",
    "        elif self.actions[action_index] == 'down' and current_row_index < self.env.nrows - 1:\n",
    "            new_row_index += 1\n",
    "        elif self.actions[action_index] == 'left' and current_column_index > 0:\n",
    "            new_column_index -= 1\n",
    "        return new_row_index, new_column_index\n",
    "    \n",
    "    def reset(self, randomizepos):\n",
    "        if randomizepos:\n",
    "            self.startx, self.starty = self._get_random_valid_pos()\n",
    "            self.x = self.startx\n",
    "            self.y = self.starty\n",
    "        else:\n",
    "            self.set_starting_pos(self.startx, self.starty)\n",
    "        return self.build_state(self.x, self.y)\n",
    "        \n",
    "    def build_state(self, *args):\n",
    "        if len(args)==1:\n",
    "            # state\n",
    "            state = args[0]\n",
    "            return np.array([state,]) \n",
    "        elif len(args)==2:\n",
    "            # x, y\n",
    "            x = args[0]\n",
    "            y = args[1]\n",
    "            return np.array([[x, y],])  \n",
    "        else:\n",
    "            raise ValueError(\"[BuildState] Invalid number of arguments passed\")\n",
    "    \n",
    "    def step(self, actionindex):\n",
    "        # Take the step and calculate new state\n",
    "        self.x, self.y = self.get_next_location(self.x, self.y, actionindex)\n",
    "        newstate = self.build_state(self.x, self.y)\n",
    "        # Calculate reward\n",
    "        reward = self.env.rewards[self.x][self.y]\n",
    "        done = self.env.is_end(self.x, self.y) or self.env.is_enemy(self.x, self.y)\n",
    "        return newstate, reward, done\n",
    "    \n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = self.model.predict(state, verbose=0)\n",
    "            if done:\n",
    "                target[0][action] = reward\n",
    "            else:\n",
    "                t = self.target_model.predict(next_state, verbose=0)[0]\n",
    "                target[0][action] = reward + self.qsettings.discount * np.amax(t)\n",
    "            self.model.fit(state, target, epochs=1, verbose=0)\n",
    "        if self.qsettings.epsilon > self.qsettings.epsilon_min:\n",
    "            self.qsettings.epsilon *= self.qsettings.epsilon_decay\n",
    "    \n",
    "    def trainDNN(self, epochs: int, epoch_max_time: int, batch_size: int, randomizepos: bool = True, verbose: bool = False):\n",
    "        self.runinfo = RunInfo(epochs, epoch_max_time)\n",
    "        self.runinfo.start_timer()\n",
    "        for epoch in range(epochs):\n",
    "            state = self.reset(randomizepos)\n",
    "            done = False\n",
    "            for time in range(epoch_max_time):\n",
    "                print(f\"Running time {time+1}/{epoch_max_time} for epoch {epoch+1}/{epochs}\", end='\\r', flush=True)\n",
    "                ### Choose an action using the epsilon-greedy algorithm\n",
    "                actionindex = self.get_next_action(state)\n",
    "                newstate, reward, done = self.step(actionindex)\n",
    "                # Store transition ( s,a,r,s',done )\n",
    "                self.memorize(state, actionindex, reward, newstate, done)\n",
    "                state = newstate\n",
    "                if done:\n",
    "                    self.update_target_model()\n",
    "                    print(\"episode: {}/{}, score: {}, e: {:.2}\"\n",
    "                          .format(epoch+1, epochs, time+1, self.qsettings.epsilon))\n",
    "                    break\n",
    "                else:\n",
    "                    if len(self.memory) > batch_size: # If enough experiences in memory -> replay\n",
    "                        self.replay(batch_size)\n",
    "                self.runinfo.add_score(epoch, time, self.qsettings.epsilon)\n",
    "        self.runinfo.end_timer()\n",
    "        traintime = self.runinfo.get_timer()\n",
    "        self.trained = True\n",
    "        print(f\"Train completed in {traintime} seconds\")\n",
    "        \n",
    "    \n",
    "    def run(self, startingpos: tuple, maxiterations: int = 10000, verbose: bool = False):\n",
    "        self.set_starting_pos(startingpos)\n",
    "        if self.env.is_enemy(self.startx, self.starty) or self.env.is_end(self.startx, self.starty):\n",
    "            return []\n",
    "        else:\n",
    "            state = self.reset(False)\n",
    "            shortestpath = []\n",
    "            shortestpath.append((self.startx, self.starty))\n",
    "            i: int = 0\n",
    "            while not (self.env.is_end(self.x, self.y) or self.env.is_enemy(self.x, self.y)):\n",
    "                actionindex = self.get_next_action(state)\n",
    "                self.x, self.y = self.get_next_location(self.x, self.y, actionindex)\n",
    "                shortestpath.append((self.x, self.y))\n",
    "                print(f\"({self.x},{self.y})\", end='\\r',flush=True)\n",
    "                i+=1\n",
    "                if (i >= maxiterations):\n",
    "                    print(f\"Reached maximum iterations {maxiterations}. Current position: ({self.x},{self.y})\")\n",
    "                    return []\n",
    "            self.ran = True\n",
    "            return shortestpath\n",
    "    \n",
    "\n",
    "    \n",
    "class Enemy(Character):\n",
    "    def __init__(self, x, y, radius = 3) -> None:\n",
    "        super().__init__(x,y)\n",
    "        self.radius = radius\n",
    "        \n",
    "    def inrange(self, x,y):\n",
    "        return Math.distance(x,self.x, y, self.y) <= self.radius\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9556fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment():\n",
    "    def __init__(self, nrows: int, ncols: int, starting_location: tuple, end_location: tuple, nenemies: int, ):\n",
    "        self.nrows = nrows\n",
    "        self.ncols = ncols\n",
    "        self.mapsize = (nrows, ncols)\n",
    "        self.end_location = end_location\n",
    "        self.endrow, self.endcol = self.end_location\n",
    "        self.nenemies = nenemies\n",
    "        \n",
    "        \n",
    "        self.enemies = []\n",
    "        self.rewards = np.full((self.nrows, self.ncols), -1.)\n",
    "        \n",
    "        self.basereward = -1\n",
    "        self.enemyreward = -300\n",
    "        self.endreward = 300\n",
    "        \n",
    "        self.__build_enemies__()\n",
    "        self.__build_rewards__()\n",
    "    \n",
    "        \n",
    "    def __build_enemies__(self):\n",
    "        if len(self.enemies) <= 0:\n",
    "            while len(self.enemies) < self.nenemies:\n",
    "                randx = np.random.randint(self.nrows)\n",
    "                randy = np.random.randint(self.ncols)\n",
    "                if (randx, randy) not in self.enemies:\n",
    "                    if (randx,randy) != self.end_location:\n",
    "                        self.enemies.append((randx, randy))\n",
    "                        \n",
    "    def __build_rewards__(self):\n",
    "        for enemy in self.enemies:\n",
    "            ob_x, ob_y = enemy\n",
    "            self.rewards[ob_x][ob_y] = self.enemyreward\n",
    "        self.rewards[self.end_location[0]][self.end_location[1]] = self.endreward\n",
    "    \n",
    "    \n",
    "    def is_enemy(self, x, y):\n",
    "        return self.rewards[x][x] == self.enemyreward\n",
    "    def is_end(self, x, y):\n",
    "        return self.rewards[x][y] == self.endreward\n",
    "    \n",
    "    def showmap(self):\n",
    "        if len(self.enemies) > 0:\n",
    "            fig, ax = plt.subplots(figsize=(9,9))\n",
    "            ax.set_title(\"Reward map\")\n",
    "            ax.set_xlabel(\"col\")\n",
    "            ax.set_ylabel(\"row\")\n",
    "            rewardmap = self.rewards\n",
    "            ax.imshow(rewardmap)\n",
    "            plt.show()      \n",
    "    \n",
    "    def showpath(self, startpos: tuple, shortestpath: list):\n",
    "        if len(shortestpath) > 0:\n",
    "            newmap = self.rewards\n",
    "            newmap[startpos[0]][startpos[1]] = -50\n",
    "            for pos in shortestpath:\n",
    "                r, c = pos\n",
    "                newmap[r][c] = 100\n",
    "            fig, ax = plt.subplots(figsize=(9,9))\n",
    "            ax.set_title(\"Reward map\")\n",
    "            ax.set_xlabel(\"col\")\n",
    "            ax.set_ylabel(\"row\")\n",
    "            ax.imshow(newmap)\n",
    "            plt.show()\n",
    "    \n",
    "    def save(self, name): \n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6855dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "e = Environment(\n",
    "    30,30,\n",
    "    (1,1),\n",
    "    (28,28),\n",
    "    100\n",
    ")\n",
    "\n",
    "agentqsettings = QSettings(epsilon=0.9, discount=0.4, learning_rate=0.001)\n",
    "a = Agent(e, 1, 1, agentqsettings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19552e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "e.showmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb941ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1/5, score: 2, e: 0.95\n",
      "episode: 2/5, score: 1, e: 0.95\n",
      "episode: 3/5, score: 1, e: 0.95\n",
      "episode: 4/5, score: 1, e: 0.95\n",
      "episode: 5/5, score: 1, e: 0.95\n",
      "Train completed in 0.2197096347808838 seconds\n"
     ]
    }
   ],
   "source": [
    "a.trainDNN(5, 90, 32, False, False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6cb9930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "print(a.qsettings.epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f58535b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "startpos = (24,1)\n",
    "shortestpath = a.run(startpos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d26e9279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(24, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(shortestpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5288f5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "e.showpath(startpos, shortestpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe9a5c3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(24, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(shortestpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb8951e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ecc6f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import progressbar\n",
    "from IPython.display import clear_output\n",
    "from pprint import pprint\n",
    "from collections import deque\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# ML\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d6c15812",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self, endposition: tuple, nenemies: int):\n",
    "        self.observation_space = (\"x\",\"y\")\n",
    "        self.action_space = [\"up\",\"down\",\"left\",\"right\"]\n",
    "        self.mapsize = (7,7)\n",
    "        if endposition[0] >= self.mapsize[0] or endposition[1] >= self.mapsize[1]:\n",
    "            raise ValueError(f\"End position outside of map of size {self.mapsize}\")\n",
    "        self.endposition = endposition\n",
    "        self.enemies = []\n",
    "        self._build_enemies(nenemies)\n",
    "        self.state = None\n",
    "    \n",
    "    def _build_enemies(self, nenemies: int):\n",
    "        while len(self.enemies) < nenemies:\n",
    "            x = np.random.randint(0, self.mapsize[0])\n",
    "            y = np.random.randint(0, self.mapsize[1])\n",
    "            if not (self.is_end(x,y)) and not (x,y) in self.enemies:\n",
    "                self.enemies.append((x,y))\n",
    "        \n",
    "    def _build_state(self, x, y):\n",
    "        return np.array([x,y], dtype=np.float32)\n",
    "            \n",
    "    def is_end(self, *args):\n",
    "        if len(args)==1:\n",
    "            # state\n",
    "            state = args[0]\n",
    "            return state == self.endposition\n",
    "        elif len(args)==2:\n",
    "            # x, y\n",
    "            x = args[0]\n",
    "            y = args[1]\n",
    "            return (x,y) == self.endposition\n",
    "        else:\n",
    "            raise ValueError(\"[IsEnd] Invalid number of arguments passed\")\n",
    "    \n",
    "    def is_enemy(self, *args):\n",
    "        if len(args)==1:\n",
    "            # state\n",
    "            state = args[0]\n",
    "            return (state[0], state[1]) in self.enemies\n",
    "        elif len(args)==2:\n",
    "            # x, y\n",
    "            x = args[0]\n",
    "            y = args[1]\n",
    "            return (x,y) in self.enemies\n",
    "        else:\n",
    "            raise ValueError(\"[IsEnd] Invalid number of arguments passed\")\n",
    "    \n",
    "    def showmap(self):\n",
    "        fig, ax = plt.subplots(figsize=(10,10))\n",
    "        plt.title(\"Environment\")\n",
    "        envmap = np.full(self.mapsize, -1)\n",
    "        for enemy in self.enemies:\n",
    "            envmap[enemy[0]][enemy[1]] = -100\n",
    "        envmap[self.endposition[0]][self.endposition[1]] = 100\n",
    "        plt.xlabel(\"x-coordinate\")\n",
    "        plt.ylabel(\"y-coorinate\")\n",
    "        ax.imshow(envmap)\n",
    "        plt.show()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = [np.random.randint(0, self.mapsize[0]), np.random.randint(0, self.mapsize[1])]\n",
    "        while self.is_end(self.state) or self.is_enemy(self.state):\n",
    "            self.state = [np.random.randint(0, self.mapsize[0]), np.random.randint(0, self.mapsize[1])]\n",
    "        return self._build_state(self.state[0], self.state[1])\n",
    "\n",
    "    def move(self, x, y, action_index):\n",
    "        newx = x\n",
    "        newy = y\n",
    "        if self.action_space[action_index] == 'up' and x > 0:\n",
    "            newx -= 1\n",
    "        elif self.action_space[action_index] == 'down' and x < self.mapsize[0] - 1:\n",
    "            newx += 1\n",
    "        elif self.action_space[action_index] == 'left' and y > 0:\n",
    "            newy -= 1\n",
    "        elif self.action_space[action_index] == 'right' and y < self.mapsize[1] - 1:\n",
    "            newy += 1\n",
    "        return newx, newy\n",
    "            \n",
    "    \n",
    "    def step(self, actionindex):\n",
    "        oldx, oldy = self.state\n",
    "        x, y = self.move(oldx, oldy, actionindex)\n",
    "        done = self.is_end(x,y)\n",
    "        if done:\n",
    "            reward = 200\n",
    "        else:\n",
    "            if self.is_enemy(x,y):\n",
    "                reward = -200\n",
    "            elif (oldx, oldy) == (x,y):\n",
    "                # went out of map (did not move)\n",
    "                reward = -100\n",
    "            else:\n",
    "                reward = -1\n",
    "        self.state = (x,y)\n",
    "        return self.state, reward, done, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c3c991ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        # Initialize attributes\n",
    "        self._state_size = len(env.observation_space)\n",
    "        self._action_size = len(env.action_space)\n",
    "        #self._optimizer = optimizer\n",
    "        \n",
    "        self.memory = deque(maxlen=3000)\n",
    "        \n",
    "        # Initialize learning settings\n",
    "        self.gamma = 0.99\n",
    "        self.epsilon = 0.98  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.1\n",
    "        \n",
    "        # Build networks\n",
    "        self.q_network = self._build_compile_model()\n",
    "        self.target_network = self._build_compile_model()\n",
    "        self.update_target_model()\n",
    "\n",
    "    def store(self, state, action, reward, next_state, terminated):\n",
    "        self.memory.append((state, action, reward, next_state, terminated))\n",
    "    \n",
    "    def _build_compile_model(self):\n",
    "        model = models.Sequential()\n",
    "        #model.add(layers.Embedding(self._state_size, 10, input_length=1))\n",
    "        #model.add(layers.Reshape((10,)))\n",
    "        model.add(layers.Dense(self.env.mapsize[0] * self.env.mapsize[1], input_dim=self._state_size, activation='relu',kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "    bias_initializer=initializers.Zeros()))\n",
    "        model.add(layers.Dense(50, activation='relu',kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "    bias_initializer=initializers.Zeros()))\n",
    "        model.add(layers.Dense(self._action_size, activation='linear',kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "    bias_initializer=initializers.Zeros()))\n",
    "        model.compile(loss='mse', optimizer=optimizers.Adam(learning_rate=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_network.set_weights(self.q_network.get_weights())\n",
    "    \n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self._action_size), \"random\"\n",
    "        q_values = self.q_network.predict(state, verbose=0)\n",
    "        maxq = np.argmax(q_values[0])\n",
    "        return maxq, \"best\"\n",
    "    \n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        \n",
    "        for state, action, reward, next_state, terminated in minibatch:\n",
    "            target = self.q_network.predict(state, verbose=0)\n",
    "            \n",
    "            if terminated:\n",
    "                target[0][action] = reward\n",
    "            else:\n",
    "                t = self.target_network.predict(next_state, verbose=0)[0]\n",
    "                target[0][action] = reward + self.gamma * np.amax(t)\n",
    "            \n",
    "            self.q_network.fit(state, target, epochs=1, verbose=False)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        \n",
    "    \n",
    "    def train(self, epochs: int, timesteps: int, batch_size: int):\n",
    "        episode_rewards = []\n",
    "        for e in range(0, epochs):\n",
    "            # Reset the environment\n",
    "            state = self.env.reset()\n",
    "            state = np.reshape(state, [1, self._state_size])\n",
    "            epochstartpos = state\n",
    "            \n",
    "            # Initialize variables\n",
    "            reward = 0\n",
    "            terminated = False\n",
    "\n",
    "            #bar = progressbar.ProgressBar(maxval=timesteps/10, widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "            #bar.start()\n",
    "            episode_reward = 0\n",
    "            for timestep in range(timesteps): \n",
    "                # Run Action\n",
    "                action, choice = self.act(state)\n",
    "                \n",
    "                # Take action\n",
    "                next_state, reward, done, info = self.env.step(action) \n",
    "                x,y = next_state\n",
    "                next_state = np.reshape(next_state, [1, self._state_size])\n",
    "                \n",
    "                self.store(state, action, reward, next_state, terminated)\n",
    "                print(f\"Timestep {timestep+1}/{timesteps} of epoch {e+1}/{epochs} --> state= {epochstartpos}/{state}/{self.env.endposition} --> choice: {choice} --> reward= {reward} --> eps= {self.epsilon}\", end='\\r', flush=True)\n",
    "                state = next_state\n",
    "                \n",
    "                #episode_reward += reward\n",
    "                if done:\n",
    "                    self.update_target_model()\n",
    "                    break\n",
    "                if len(self.memory) > batch_size:\n",
    "                    self.replay(batch_size)\n",
    "            episode_rewards.append(episode_reward)\n",
    "        return episode_rewards\n",
    "            \n",
    "    \n",
    "    def run(self, startpos):\n",
    "        done = False\n",
    "        self.env.reset()\n",
    "        state = np.reshape(startpos, [1, self._state_size])\n",
    "        shortestpath = []\n",
    "        shortestpath.append(state)\n",
    "        while not done:\n",
    "            action = self.act(state)\n",
    "            next_state, reward, done, info = self.env.step(action) \n",
    "            next_state = np.reshape(next_state, [1, self._state_size])\n",
    "            shortestpath.append(next_state)\n",
    "            print(next_state, end='\\r', flush=True)\n",
    "            state = next_state\n",
    "        return shortestpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f181d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment((6,6), 5)\n",
    "a = Agent(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7d5ff6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.showmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a3a5707b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestep 55/400 of epoch 3/20 --> state= [[5. 3.]]/[[6 0]]/(6, 6) --> choice: best --> reward= -1 --> eps= 0.59963640085948720123\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [164], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m episoderewards \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [161], line 99\u001b[0m, in \u001b[0;36mAgent.train\u001b[0;34m(self, epochs, timesteps, batch_size)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory) \u001b[38;5;241m>\u001b[39m batch_size:\n\u001b[0;32m---> 99\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     episode_rewards\u001b[38;5;241m.\u001b[39mappend(episode_reward)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m episode_rewards\n",
      "Cell \u001b[0;32mIn [161], line 53\u001b[0m, in \u001b[0;36mAgent.replay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     50\u001b[0m minibatch \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory, batch_size)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m state, action, reward, next_state, terminated \u001b[38;5;129;01min\u001b[39;00m minibatch:\n\u001b[0;32m---> 53\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_network\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m terminated:\n\u001b[1;32m     56\u001b[0m         target[\u001b[38;5;241m0\u001b[39m][action] \u001b[38;5;241m=\u001b[39m reward\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:2220\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2211\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m   2212\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2213\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2214\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2217\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   2218\u001b[0m         )\n\u001b[0;32m-> 2220\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2224\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2228\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2230\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2231\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   2234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/data_adapter.py:1582\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/data_adapter.py:1262\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[1;32m   1261\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1268\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1277\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/data_adapter.py:347\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m         flat_dataset \u001b[38;5;241m=\u001b[39m flat_dataset\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m1024\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(epochs)\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m flat_dataset\n\u001b[0;32m--> 347\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mindices_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslice_batch_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslice_inputs(indices_dataset, inputs)\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:2245\u001b[0m, in \u001b[0;36mDatasetV2.flat_map\u001b[0;34m(self, map_func, name)\u001b[0m\n\u001b[1;32m   2212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_map\u001b[39m(\u001b[38;5;28mself\u001b[39m, map_func, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2213\u001b[0m   \u001b[38;5;124;03m\"\"\"Maps `map_func` across this dataset and flattens the result.\u001b[39;00m\n\u001b[1;32m   2214\u001b[0m \n\u001b[1;32m   2215\u001b[0m \u001b[38;5;124;03m  The type signature is:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2243\u001b[0m \u001b[38;5;124;03m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2245\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFlatMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:5492\u001b[0m, in \u001b[0;36mFlatMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, name)\u001b[0m\n\u001b[1;32m   5490\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_structure \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39moutput_structure\u001b[38;5;241m.\u001b[39m_element_spec  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   5491\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m-> 5492\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_map_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5493\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m   5494\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_func\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_func\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5496\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_common_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5497\u001b[0m \u001b[38;5;28msuper\u001b[39m(FlatMapDataset, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(input_dataset, variant_tensor)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py:2357\u001b[0m, in \u001b[0;36mflat_map_dataset\u001b[0;34m(input_dataset, other_arguments, f, output_types, output_shapes, metadata, name)\u001b[0m\n\u001b[1;32m   2355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   2356\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2357\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2358\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFlatMapDataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother_arguments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2359\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2360\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   2362\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "episoderewards = a.train(20, 400, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04dfdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(14,6))\n",
    "plt.plot(episoderewards)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d604d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.run((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5d0e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(a.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bea2fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
